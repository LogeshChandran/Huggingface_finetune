{"metadata":{"colab":{"name":"Welcome To Colab","provenance":[],"gpuType":"V28","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7b2b26fe6c8b46c288eb7585927e83e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edfe48c41a78466ea2feb5a9df80e44e","IPY_MODEL_244db535c9834a86b781b11a69db76d9","IPY_MODEL_7f9bfa1e78e74a8ba08367cc35959772"],"layout":"IPY_MODEL_eafbba14e9c843ccbc71912e6643c0d0"}},"edfe48c41a78466ea2feb5a9df80e44e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0816c7056030469ca7c9600691c75b92","placeholder":"​","style":"IPY_MODEL_3561df53dc504f1fb366b038af14e874","value":"README.md: 100%"}},"244db535c9834a86b781b11a69db76d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_341afe45d0344747837eb1cd346d03b4","max":988,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd8d5186c95e4fef994a9e6e152fbcad","value":988}},"7f9bfa1e78e74a8ba08367cc35959772":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83847f57e52b413c88a562298c7275fe","placeholder":"​","style":"IPY_MODEL_a12fdcd9b3464ba5b4402776d51849fa","value":" 988/988 [00:00&lt;00:00, 13.8kB/s]"}},"eafbba14e9c843ccbc71912e6643c0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0816c7056030469ca7c9600691c75b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3561df53dc504f1fb366b038af14e874":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"341afe45d0344747837eb1cd346d03b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd8d5186c95e4fef994a9e6e152fbcad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83847f57e52b413c88a562298c7275fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a12fdcd9b3464ba5b4402776d51849fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82755b866009401a8155aa56a0668a51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da28ce03235f4fc7bbaf0fd9992210c1","IPY_MODEL_5001d549126e441f8073639670cb6fd8","IPY_MODEL_b61fddc3619e4adea1f203f129c18a1e"],"layout":"IPY_MODEL_3025af8584494a63917bbf1789e7fcd6"}},"da28ce03235f4fc7bbaf0fd9992210c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a465a3d3bc54aa4bc2bfb52df3aae6c","placeholder":"​","style":"IPY_MODEL_772e70f8bdd9430486f2813badb7ac06","value":"Map: 100%"}},"5001d549126e441f8073639670cb6fd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8ff3edfe3a0493ab0713e4cb219ab0c","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5cc408f472b84b2aa8b2b033aab0f0e5","value":10}},"b61fddc3619e4adea1f203f129c18a1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16f4ce99dc1045b496805327e96452a9","placeholder":"​","style":"IPY_MODEL_28ea0fe2f5e04bd3beeb4ff6bc494e96","value":" 10/10 [00:00&lt;00:00, 161.48 examples/s]"}},"3025af8584494a63917bbf1789e7fcd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a465a3d3bc54aa4bc2bfb52df3aae6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"772e70f8bdd9430486f2813badb7ac06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8ff3edfe3a0493ab0713e4cb219ab0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc408f472b84b2aa8b2b033aab0f0e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16f4ce99dc1045b496805327e96452a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ea0fe2f5e04bd3beeb4ff6bc494e96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21a72ecb915e4d1c91919b2d62b1d030":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42eb28f8acb1427aa1ff6433ee232f50","IPY_MODEL_efcd92fae44b45369e8217dcaff53e1f","IPY_MODEL_fc74b6c44934407abb43f841ee5b0f0c"],"layout":"IPY_MODEL_01fe12f748754f75a440eea7e2407150"}},"42eb28f8acb1427aa1ff6433ee232f50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1e5ef3f49745889fcf5c51acac31e6","placeholder":"​","style":"IPY_MODEL_e669c40cd3594bb99e74c9c281b14426","value":"Map: 100%"}},"efcd92fae44b45369e8217dcaff53e1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_398da9c576464ba5bc119c80743ccfe3","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63a761164cdf43c89efe95ab88ea36fe","value":10}},"fc74b6c44934407abb43f841ee5b0f0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_884ed84e8cfc40a296e4099a596651da","placeholder":"​","style":"IPY_MODEL_d0189f4c1c6840c1a9f22d0dab04f14e","value":" 10/10 [00:00&lt;00:00, 122.84 examples/s]"}},"01fe12f748754f75a440eea7e2407150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1e5ef3f49745889fcf5c51acac31e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e669c40cd3594bb99e74c9c281b14426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"398da9c576464ba5bc119c80743ccfe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a761164cdf43c89efe95ab88ea36fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"884ed84e8cfc40a296e4099a596651da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0189f4c1c6840c1a9f22d0dab04f14e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f587d02e00294275b938b8cec20dac76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c656e5c97194be6be6deb3783c5f173","IPY_MODEL_e04628e035f34d719881ee126c1b448b","IPY_MODEL_934ce098c3d84d0ab3fb3d1c01eb4257"],"layout":"IPY_MODEL_32217b02deda44758ad4b8f0d477054d"}},"9c656e5c97194be6be6deb3783c5f173":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f12a0a1b4a34a63a49719b060de93aa","placeholder":"​","style":"IPY_MODEL_1b14fbdbaca9462284a9ca4e9b2fff6b","value":"Map: 100%"}},"e04628e035f34d719881ee126c1b448b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ded8905f0744ffbaee8e1b4e842679","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66b311b53fc04345ac47f2d472924dbf","value":10}},"934ce098c3d84d0ab3fb3d1c01eb4257":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6129c8e6e200441487fdd6e255ce1ec0","placeholder":"​","style":"IPY_MODEL_4499b8e67d0d46b3a2c8cb786105ff4d","value":" 10/10 [00:00&lt;00:00, 138.90 examples/s]"}},"32217b02deda44758ad4b8f0d477054d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f12a0a1b4a34a63a49719b060de93aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b14fbdbaca9462284a9ca4e9b2fff6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ded8905f0744ffbaee8e1b4e842679":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b311b53fc04345ac47f2d472924dbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6129c8e6e200441487fdd6e255ce1ec0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4499b8e67d0d46b3a2c8cb786105ff4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67691184378a460fabbaa9deffbf2942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c140e47458344daa17ce2135969ab66","IPY_MODEL_412ccc11949e4e7493ba9add45c32ac0","IPY_MODEL_27e7a671a85d4771899b7a39021798b3"],"layout":"IPY_MODEL_7e153a93915a4e0887827d46f7f6c42d"}},"1c140e47458344daa17ce2135969ab66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78538f7b0f544cb29717a61ff6243ba8","placeholder":"​","style":"IPY_MODEL_4348ac706dad4b6cbc6f4e3f4f61a625","value":"Downloading builder script: 100%"}},"412ccc11949e4e7493ba9add45c32ac0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5ed0f6efbd43e8b94f1738a6eeb025","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e05224098c24064bec6be13e8195c89","value":6270}},"27e7a671a85d4771899b7a39021798b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b01b2e24f664d2799a03bf5bca74d38","placeholder":"​","style":"IPY_MODEL_55a1ef07e4a247d7bad3ffabd3e016a1","value":" 6.27k/6.27k [00:00&lt;00:00, 338kB/s]"}},"7e153a93915a4e0887827d46f7f6c42d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78538f7b0f544cb29717a61ff6243ba8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4348ac706dad4b6cbc6f4e3f4f61a625":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc5ed0f6efbd43e8b94f1738a6eeb025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e05224098c24064bec6be13e8195c89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b01b2e24f664d2799a03bf5bca74d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a1ef07e4a247d7bad3ffabd3e016a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50387fd8bb3d42d3a7e4bd6792b4361f":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_1693edd15df64bb8b92aff1e38afbbb0","IPY_MODEL_989bf836f4744876a8a3bf4915c8d1f4"],"layout":"IPY_MODEL_55bf703c4da54e0387fef342cfeac073"}},"1693edd15df64bb8b92aff1e38afbbb0":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4c5e41701f43f4a40081fc9bad09da","placeholder":"​","style":"IPY_MODEL_107098a7f3d04c23941991632b8d942f","value":"0.057 MB of 0.057 MB uploaded\r"}},"989bf836f4744876a8a3bf4915c8d1f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b153982537a4f8a927e980481ef2fc4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c84b0ed37d824200b68483672d1f6e13","value":1}},"55bf703c4da54e0387fef342cfeac073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f4c5e41701f43f4a40081fc9bad09da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107098a7f3d04c23941991632b8d942f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b153982537a4f8a927e980481ef2fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84b0ed37d824200b68483672d1f6e13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1826726d26a7414b945e8ca9343be264":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa14e71b2e754c96b8ab3c53b36af066","IPY_MODEL_c91f427af63e4da2b4235af00d2e549e","IPY_MODEL_5d1e9e3cb6334a07b2f3eeb8d65dbe94"],"layout":"IPY_MODEL_eff808a76f2f4d27bd5aea6404ec640a"}},"aa14e71b2e754c96b8ab3c53b36af066":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe6c6893fc614194b0c15420eef84534","placeholder":"​","style":"IPY_MODEL_f0fc6f87b73f44d1aa4ac620d865f7dd","value":"model.safetensors: 100%"}},"c91f427af63e4da2b4235af00d2e549e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc1f43f184a04c2d85107ed9403447c5","max":1625422896,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b51c00e12634564b3fc274907e5fc16","value":1625422896}},"5d1e9e3cb6334a07b2f3eeb8d65dbe94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30c0e26666db452493bde1bb58202a98","placeholder":"​","style":"IPY_MODEL_0deb1f02e16243f1a6e70e0dfc07676a","value":" 1.63G/1.63G [00:44&lt;00:00, 40.5MB/s]"}},"eff808a76f2f4d27bd5aea6404ec640a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe6c6893fc614194b0c15420eef84534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0fc6f87b73f44d1aa4ac620d865f7dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc1f43f184a04c2d85107ed9403447c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b51c00e12634564b3fc274907e5fc16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30c0e26666db452493bde1bb58202a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0deb1f02e16243f1a6e70e0dfc07676a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9fa392542bc4631b3ec1d1f8d3e4cbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a800850a4fa74e11aff0491448eaaafb","IPY_MODEL_474d6173d7c648b381fd4aa623e26cfc","IPY_MODEL_1e6a7c50b0854fa084429d44c2af6d0c"],"layout":"IPY_MODEL_391127497fb44b819c35daac929a7890"}},"a800850a4fa74e11aff0491448eaaafb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3aa91967a0346fa9cb9ddd4f15c6174","placeholder":"​","style":"IPY_MODEL_62b79ee93bc14a4e8e5da5df21fb8e5b","value":"README.md: 100%"}},"474d6173d7c648b381fd4aa623e26cfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5499836a37ee496cb204bee0a55d0b55","max":5174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25a04dc8d51748569c0fd06f938169a3","value":5174}},"1e6a7c50b0854fa084429d44c2af6d0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0460fcb239fe4d88be3df55545df7008","placeholder":"​","style":"IPY_MODEL_de2216fa268b435094278ec3d4dcf579","value":" 5.17k/5.17k [00:00&lt;00:00, 149kB/s]"}},"391127497fb44b819c35daac929a7890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3aa91967a0346fa9cb9ddd4f15c6174":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b79ee93bc14a4e8e5da5df21fb8e5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5499836a37ee496cb204bee0a55d0b55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a04dc8d51748569c0fd06f938169a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0460fcb239fe4d88be3df55545df7008":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de2216fa268b435094278ec3d4dcf579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"TPU","language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/LogeshChandran/Huggingface_finetune/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"### Testing","metadata":{"id":"TAX9rbxRhpnE"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vw5E5jhviJze","outputId":"ae1f766f-f14d-4366-b0b7-e38fa7d82f03","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting datasets\n\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n\nCollecting pyarrow>=15.0.0 (from datasets)\n\n  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n\nCollecting dill<0.3.9,>=0.3.0 (from datasets)\n\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n\nCollecting xxhash (from datasets)\n\n  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n\nCollecting multiprocess (from datasets)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n\nRequirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n\nDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n\n  Attempting uninstall: pyarrow\n\n    Found existing installation: pyarrow 14.0.2\n\n    Uninstalling pyarrow-14.0.2:\n\n      Successfully uninstalled pyarrow-14.0.2\n\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n\n\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# ds = load_dataset(\"Logeshkc/newsroom\")","metadata":{"id":"GPnaW3LFhvGv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(first_1000_dataset)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ru-T2cKviqCt","outputId":"c149c9f7-a042-4878-d503-df8170c78f2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Dataset({\n\n    features: ['url', 'archive', 'title', 'date', 'text', 'summary', 'compression', 'coverage', 'density', 'compression_bin', 'coverage_bin', 'density_bin', '__index_level_0__'],\n\n    num_rows: 1000\n\n})\n"}]},{"cell_type":"code","source":"! pip install transformers\n! pip install datasets\n! pip install sentencepiece\n! pip install rouge_score\n! pip install wandb\n! pip install evaluate\n! pip install torch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFZPbJxyllu_","outputId":"e578a83e-5274-49a3-c711-7f0d73181007","execution":{"iopub.status.busy":"2024-09-19T09:12:08.564201Z","iopub.execute_input":"2024-09-19T09:12:08.564558Z","iopub.status.idle":"2024-09-19T09:13:42.074227Z","shell.execute_reply.started":"2024-09-19T09:12:08.564526Z","shell.execute_reply":"2024-09-19T09:13:42.073041Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c451b0487c0cdde7cacf8077b9d7db232d480b32ca879d772ce515f733e4e07e\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install ipywidgets","metadata":{"execution":{"iopub.status.busy":"2024-09-19T02:23:16.210372Z","iopub.execute_input":"2024-09-19T02:23:16.210701Z","iopub.status.idle":"2024-09-19T02:23:29.454124Z","shell.execute_reply.started":"2024-09-19T02:23:16.210667Z","shell.execute_reply":"2024-09-19T02:23:29.453160Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.29.4)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.8)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.1)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (26.0.3)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.1.2)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\nRequirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.22.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\nRequirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.12.5)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\nRequirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.2)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.6.0)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.9.0.20240316)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)  # This strategy will distribute the computations on TPUs\nprint(\"All TPU cores are initialized\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! wandb login --relogin","metadata":{"execution":{"iopub.status.busy":"2024-09-18T16:23:37.863614Z","iopub.execute_input":"2024-09-18T16:23:37.864461Z","iopub.status.idle":"2024-09-18T16:24:30.325894Z","shell.execute_reply.started":"2024-09-18T16:23:37.864418Z","shell.execute_reply":"2024-09-18T16:24:30.324759Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \nAborted!\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport datasets\nimport evaluate\nfrom transformers import (\n    AutoModelForSeq2SeqLM,\n    AutoTokenizer,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    DataCollatorForSeq2Seq,\n)\n\nfrom tabulate import tabulate\nimport nltk\nfrom datetime import datetime\n\n\n#f1112bec2d2a9b22ac73033c91b302f44085a442\n\n\nWANDB_INTEGRATION = True\n# WANDB_INTEGRATION = False\nif WANDB_INTEGRATION:\n    import wandb\n    wandb.init()\n    wandb.login()","metadata":{"id":"LI6AM4MMiGGJ","execution":{"iopub.status.busy":"2024-09-19T09:13:42.076421Z","iopub.execute_input":"2024-09-19T09:13:42.076787Z","iopub.status.idle":"2024-09-19T09:14:47.901649Z","shell.execute_reply.started":"2024-09-19T09:13:42.076749Z","shell.execute_reply":"2024-09-19T09:14:47.900688Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240919_091417-msors8ah</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/logeshkc-student/uncategorized/runs/msors8ah' target=\"_blank\">colorful-haze-7</a></strong> to <a href='https://wandb.ai/logeshkc-student/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/logeshkc-student/uncategorized' target=\"_blank\">https://wandb.ai/logeshkc-student/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/logeshkc-student/uncategorized/runs/msors8ah' target=\"_blank\">https://wandb.ai/logeshkc-student/uncategorized/runs/msors8ah</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"facebook/bart-large-cnn\"\ndataset_name = \"Logeshkc/newsroom\"","metadata":{"id":"qBsPrv4qlgP2","execution":{"iopub.status.busy":"2024-09-19T09:14:47.902859Z","iopub.execute_input":"2024-09-19T09:14:47.903245Z","iopub.status.idle":"2024-09-19T09:14:47.908498Z","shell.execute_reply.started":"2024-09-19T09:14:47.903201Z","shell.execute_reply":"2024-09-19T09:14:47.907588Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T09:14:47.910949Z","iopub.execute_input":"2024-09-19T09:14:47.911561Z","iopub.status.idle":"2024-09-19T09:14:47.919799Z","shell.execute_reply.started":"2024-09-19T09:14:47.911507Z","shell.execute_reply":"2024-09-19T09:14:47.918928Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"facebook/bart-large-cnn\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"id":"78Q5dGcOm3UM","execution":{"iopub.status.busy":"2024-09-19T09:14:47.920799Z","iopub.execute_input":"2024-09-19T09:14:47.921186Z","iopub.status.idle":"2024-09-19T09:15:49.668248Z","shell.execute_reply.started":"2024-09-19T09:14:47.921153Z","shell.execute_reply":"2024-09-19T09:15:49.667234Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f69a79408a84ed19d156ee952dba7ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f3eaab857448fea44f130112671ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d73e694c7f747b1ba4dc3ace6da1fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b9a820f537a4d8e9dae7038dfd917c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e049fd98cf234c4e9a3aac098dc7654c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a2cb9a0ac7242e9918c13a3b93005c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_max_length = 256  # demo\ndecoder_max_length = 64","metadata":{"id":"hqfmIrLznM2P","execution":{"iopub.status.busy":"2024-09-19T09:15:49.669517Z","iopub.execute_input":"2024-09-19T09:15:49.669830Z","iopub.status.idle":"2024-09-19T09:15:49.676259Z","shell.execute_reply.started":"2024-09-19T09:15:49.669797Z","shell.execute_reply":"2024-09-19T09:15:49.675232Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset,Dataset\nfrom itertools import islice\n\ndef get_first_n_records(dataset_name, split_name, n_records):\n    ds = load_dataset(dataset_name, split=split_name, streaming=True)\n    first_n = list(islice(ds, n_records))\n    first_n_dataset = Dataset.from_list(first_n)\n\n    return first_n_dataset.to_pandas()\n\ntrain_n_records = 500000\ntest_n_records = 50000\neval_n_records = 50000\n\ntrain_df = get_first_n_records(dataset_name, \"train\", train_n_records)\ntest_df = get_first_n_records(dataset_name, \"test\", test_n_records)\neval_df = get_first_n_records(dataset_name, \"validation\", eval_n_records)\n\n# print(\"Train Dataset:\", train_df)\n# print(\"Test Dataset:\", test_df)\n# print(\"Eval Dataset:\", eval_df)\n","metadata":{"id":"X78uMbqUnd1V","colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["7b2b26fe6c8b46c288eb7585927e83e3","edfe48c41a78466ea2feb5a9df80e44e","244db535c9834a86b781b11a69db76d9","7f9bfa1e78e74a8ba08367cc35959772","eafbba14e9c843ccbc71912e6643c0d0","0816c7056030469ca7c9600691c75b92","3561df53dc504f1fb366b038af14e874","341afe45d0344747837eb1cd346d03b4","bd8d5186c95e4fef994a9e6e152fbcad","83847f57e52b413c88a562298c7275fe","a12fdcd9b3464ba5b4402776d51849fa"]},"outputId":"d9276d93-1bf0-4ccc-a7c7-3dcf717eb273","execution":{"iopub.status.busy":"2024-09-19T09:15:49.677811Z","iopub.execute_input":"2024-09-19T09:15:49.678251Z","iopub.status.idle":"2024-09-19T09:29:10.130211Z","shell.execute_reply.started":"2024-09-19T09:15:49.678204Z","shell.execute_reply":"2024-09-19T09:29:10.128764Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/988 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79d7a4b2b55b43b28f0d8b4db7b53a80"}},"metadata":{}}]},{"cell_type":"code","source":"train_df = train_df[train_df[:]['density_bin'] == 'abstractive']\ntest_df = test_df[test_df[:]['density_bin'] == 'abstractive']\neval_df = eval_df[eval_df[:]['density_bin'] == 'abstractive']","metadata":{"id":"IBTG6IY-svj1","execution":{"iopub.status.busy":"2024-09-19T09:29:10.131744Z","iopub.execute_input":"2024-09-19T09:29:10.132069Z","iopub.status.idle":"2024-09-19T09:29:10.486264Z","shell.execute_reply.started":"2024-09-19T09:29:10.132013Z","shell.execute_reply":"2024-09-19T09:29:10.485223Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df[:10]\n# test_df = test_df[:10]\n# eval_df = eval_df[:10]","metadata":{"id":"enPyCgKj12bJ","execution":{"iopub.status.busy":"2024-09-19T09:29:10.487758Z","iopub.execute_input":"2024-09-19T09:29:10.488103Z","iopub.status.idle":"2024-09-19T09:29:10.493720Z","shell.execute_reply.started":"2024-09-19T09:29:10.488061Z","shell.execute_reply":"2024-09-19T09:29:10.492546Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def remove_special_characters(df,column_name):\n    df[column_name+'_clean'] = df[column_name].replace(r'\\n', '.', regex=True).replace(r'\\.\\.+', '.', regex=True).replace(r'[^\\w\\s.]', '', regex=True).replace(r'[\\t]', '', regex=True)\n    return df","metadata":{"id":"_4ZvpYvIx7zp","execution":{"iopub.status.busy":"2024-09-19T09:29:10.497199Z","iopub.execute_input":"2024-09-19T09:29:10.497473Z","iopub.status.idle":"2024-09-19T09:29:10.525731Z","shell.execute_reply.started":"2024-09-19T09:29:10.497443Z","shell.execute_reply":"2024-09-19T09:29:10.524858Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df = remove_special_characters(train_df,'text')\ntrain_df = remove_special_characters(train_df,'summary')\n\ntest_df = remove_special_characters(test_df,'text')\ntest_df = remove_special_characters(test_df,'summary')\n\neval_df = remove_special_characters(eval_df,'text')\neval_df = remove_special_characters(eval_df,'summary')","metadata":{"id":"449eA0dfo_13","execution":{"iopub.status.busy":"2024-09-19T09:29:10.527430Z","iopub.execute_input":"2024-09-19T09:29:10.527944Z","iopub.status.idle":"2024-09-19T09:29:40.005235Z","shell.execute_reply.started":"2024-09-19T09:29:10.527897Z","shell.execute_reply":"2024-09-19T09:29:40.004117Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df.head(1)","metadata":{"id":"DCHlzy-prhHQ","outputId":"cfb14b93-a201-42d8-e8d7-3016c75be037","colab":{"base_uri":"https://localhost:8080/","height":188},"execution":{"iopub.status.busy":"2024-09-19T09:29:40.006614Z","iopub.execute_input":"2024-09-19T09:29:40.007033Z","iopub.status.idle":"2024-09-19T09:29:40.032751Z","shell.execute_reply.started":"2024-09-19T09:29:40.006985Z","shell.execute_reply":"2024-09-19T09:29:40.031793Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                  url  \\\n12  http://www.telegraph.co.uk/aboutus/careers-at-...   \n\n                                              archive  \\\n12  http://web.archive.org/web/20091101154544id_/h...   \n\n                                        title                       date  \\\n12  Careers at Telegraph Media Group: Culture 1970-08-21 12:51:41.154544   \n\n                                                 text  \\\n12  Published: 2:56PM BST 09 Oct 2009\\n\\nMedia is ...   \n\n                                              summary  compression  coverage  \\\n12  Telegraph Media Group operate a culture of kno...    10.928571  0.571429   \n\n     density compression_bin coverage_bin  density_bin  __index_level_0__  \\\n12  0.714286             low          low  abstractive                 12   \n\n                                           text_clean  \\\n12  Published 256PM BST 09 Oct 2009.Media is a ver...   \n\n                                        summary_clean  \n12  Telegraph Media Group operate a culture of kno...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>archive</th>\n      <th>title</th>\n      <th>date</th>\n      <th>text</th>\n      <th>summary</th>\n      <th>compression</th>\n      <th>coverage</th>\n      <th>density</th>\n      <th>compression_bin</th>\n      <th>coverage_bin</th>\n      <th>density_bin</th>\n      <th>__index_level_0__</th>\n      <th>text_clean</th>\n      <th>summary_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>http://www.telegraph.co.uk/aboutus/careers-at-...</td>\n      <td>http://web.archive.org/web/20091101154544id_/h...</td>\n      <td>Careers at Telegraph Media Group: Culture</td>\n      <td>1970-08-21 12:51:41.154544</td>\n      <td>Published: 2:56PM BST 09 Oct 2009\\n\\nMedia is ...</td>\n      <td>Telegraph Media Group operate a culture of kno...</td>\n      <td>10.928571</td>\n      <td>0.571429</td>\n      <td>0.714286</td>\n      <td>low</td>\n      <td>low</td>\n      <td>abstractive</td>\n      <td>12</td>\n      <td>Published 256PM BST 09 Oct 2009.Media is a ver...</td>\n      <td>Telegraph Media Group operate a culture of kno...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df.head(1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"a8fqcRz0gfBg","outputId":"33e389ab-13e9-455a-f7b1-5407fd3941e5","execution":{"iopub.status.busy":"2024-09-19T09:29:40.033952Z","iopub.execute_input":"2024-09-19T09:29:40.034398Z","iopub.status.idle":"2024-09-19T09:29:40.052317Z","shell.execute_reply.started":"2024-09-19T09:29:40.034349Z","shell.execute_reply":"2024-09-19T09:29:40.051261Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                 url  \\\n3  http://www.forbes.com/2010/05/12/iphone-blackb...   \n\n                                             archive  \\\n3  http://web.archive.org/web/20120312144834id_/h...   \n\n                                        title                       date  \\\n3  In Pictures: 10 Ways To Fix Your Cellphone 1970-08-21 20:58:32.144834   \n\n                                                text  \\\n3  Like all gadgets, cellphones can break. In fac...   \n\n                                             summary  compression  coverage  \\\n3  Simple home remedies for repairing your mobile...       4.3125       0.5   \n\n   density compression_bin coverage_bin  density_bin  __index_level_0__  \\\n3    0.625             low          low  abstractive                  3   \n\n                                          text_clean  \\\n3  Like all gadgets cellphones can break. In fact...   \n\n                                       summary_clean  \n3  Simple home remedies for repairing your mobile...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>archive</th>\n      <th>title</th>\n      <th>date</th>\n      <th>text</th>\n      <th>summary</th>\n      <th>compression</th>\n      <th>coverage</th>\n      <th>density</th>\n      <th>compression_bin</th>\n      <th>coverage_bin</th>\n      <th>density_bin</th>\n      <th>__index_level_0__</th>\n      <th>text_clean</th>\n      <th>summary_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>http://www.forbes.com/2010/05/12/iphone-blackb...</td>\n      <td>http://web.archive.org/web/20120312144834id_/h...</td>\n      <td>In Pictures: 10 Ways To Fix Your Cellphone</td>\n      <td>1970-08-21 20:58:32.144834</td>\n      <td>Like all gadgets, cellphones can break. In fac...</td>\n      <td>Simple home remedies for repairing your mobile...</td>\n      <td>4.3125</td>\n      <td>0.5</td>\n      <td>0.625</td>\n      <td>low</td>\n      <td>low</td>\n      <td>abstractive</td>\n      <td>3</td>\n      <td>Like all gadgets cellphones can break. In fact...</td>\n      <td>Simple home remedies for repairing your mobile...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eval_df.head(1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"25wI5VS1gfwX","outputId":"7678c72b-afbc-4fcd-d487-6038adfb87b7","execution":{"iopub.status.busy":"2024-09-19T09:29:40.053627Z","iopub.execute_input":"2024-09-19T09:29:40.054153Z","iopub.status.idle":"2024-09-19T09:29:40.074067Z","shell.execute_reply.started":"2024-09-19T09:29:40.054109Z","shell.execute_reply":"2024-09-19T09:29:40.073002Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                 url  \\\n0  http://www.foxsports.com/baseball/xchange/team...   \n\n                                             archive  \\\n0  http://web.archive.org/web/19980117162148id_/h...   \n\n                      title                       date  \\\n0  Pro Sports Xchange notes 1970-08-20 06:01:57.162148   \n\n                                                text  \\\n0  So sayeth Padre general manager Kevin Towers.\\...   \n\n                          summary  compression  coverage  density  \\\n0  SAN DIEGO PADRES team notebook        209.0       0.8      1.2   \n\n  compression_bin coverage_bin  density_bin  __index_level_0__  \\\n0            high       medium  abstractive                  0   \n\n                                          text_clean  \\\n0  So sayeth Padre general manager Kevin Towers.L...   \n\n                    summary_clean  \n0  SAN DIEGO PADRES team notebook  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>archive</th>\n      <th>title</th>\n      <th>date</th>\n      <th>text</th>\n      <th>summary</th>\n      <th>compression</th>\n      <th>coverage</th>\n      <th>density</th>\n      <th>compression_bin</th>\n      <th>coverage_bin</th>\n      <th>density_bin</th>\n      <th>__index_level_0__</th>\n      <th>text_clean</th>\n      <th>summary_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://www.foxsports.com/baseball/xchange/team...</td>\n      <td>http://web.archive.org/web/19980117162148id_/h...</td>\n      <td>Pro Sports Xchange notes</td>\n      <td>1970-08-20 06:01:57.162148</td>\n      <td>So sayeth Padre general manager Kevin Towers.\\...</td>\n      <td>SAN DIEGO PADRES team notebook</td>\n      <td>209.0</td>\n      <td>0.8</td>\n      <td>1.2</td>\n      <td>high</td>\n      <td>medium</td>\n      <td>abstractive</td>\n      <td>0</td>\n      <td>So sayeth Padre general manager Kevin Towers.L...</td>\n      <td>SAN DIEGO PADRES team notebook</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df[['text_clean','summary_clean']])\ntest_dataset = Dataset.from_pandas(test_df[['text_clean','summary_clean']])\neval_dataset = Dataset.from_pandas(eval_df[['text_clean','summary_clean']])","metadata":{"id":"gyDLuNQn4Bp2","execution":{"iopub.status.busy":"2024-09-19T09:29:40.075276Z","iopub.execute_input":"2024-09-19T09:29:40.075595Z","iopub.status.idle":"2024-09-19T09:29:44.144177Z","shell.execute_reply.started":"2024-09-19T09:29:40.075563Z","shell.execute_reply":"2024-09-19T09:29:44.143088Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n  text, summary = batch[\"text_clean\"], batch[\"summary_clean\"]\n  text_tokenized = tokenizer(text, max_length=max_source_length, truncation=True)\n  summary_tokenized = tokenizer(summary, max_length=max_target_length, truncation=True)\n  batch = {k: v for k, v in text_tokenized.items()}\n  batch[\"labels\"] = [\n      -100 if token == tokenizer.pad_token_id else token\n      for token in summary_tokenized[\"input_ids\"]\n  ]\n  return batch","metadata":{"id":"8w59RBh15n0c","execution":{"iopub.status.busy":"2024-09-19T09:29:44.145476Z","iopub.execute_input":"2024-09-19T09:29:44.145798Z","iopub.status.idle":"2024-09-19T09:29:44.152859Z","shell.execute_reply.started":"2024-09-19T09:29:44.145764Z","shell.execute_reply":"2024-09-19T09:29:44.151874Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"id":"X5HZFsuZ1duJ","outputId":"974b4d7f-000a-481f-f0df-55bfde108dec","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-09-19T09:29:44.153987Z","iopub.execute_input":"2024-09-19T09:29:44.154326Z","iopub.status.idle":"2024-09-19T09:29:44.163430Z","shell.execute_reply.started":"2024-09-19T09:29:44.154289Z","shell.execute_reply":"2024-09-19T09:29:44.162602Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text_clean', 'summary_clean', '__index_level_0__'],\n    num_rows: 148979\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train_dataset.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=train_dataset.column_names,\n)\n\ntest_data = test_dataset.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=test_dataset.column_names,\n)\n\neval_data = eval_dataset.map(\n    lambda batch: batch_tokenize_preprocess(\n        batch, tokenizer, encoder_max_length, decoder_max_length\n    ),\n    batched=True,\n    remove_columns=eval_dataset.column_names,\n)\n","metadata":{"id":"AxZq4eIi2tro","outputId":"dfff927c-91b7-42e4-8633-8fd678631cdc","colab":{"base_uri":"https://localhost:8080/","height":133,"referenced_widgets":["82755b866009401a8155aa56a0668a51","da28ce03235f4fc7bbaf0fd9992210c1","5001d549126e441f8073639670cb6fd8","b61fddc3619e4adea1f203f129c18a1e","3025af8584494a63917bbf1789e7fcd6","9a465a3d3bc54aa4bc2bfb52df3aae6c","772e70f8bdd9430486f2813badb7ac06","f8ff3edfe3a0493ab0713e4cb219ab0c","5cc408f472b84b2aa8b2b033aab0f0e5","16f4ce99dc1045b496805327e96452a9","28ea0fe2f5e04bd3beeb4ff6bc494e96","21a72ecb915e4d1c91919b2d62b1d030","42eb28f8acb1427aa1ff6433ee232f50","efcd92fae44b45369e8217dcaff53e1f","fc74b6c44934407abb43f841ee5b0f0c","01fe12f748754f75a440eea7e2407150","9f1e5ef3f49745889fcf5c51acac31e6","e669c40cd3594bb99e74c9c281b14426","398da9c576464ba5bc119c80743ccfe3","63a761164cdf43c89efe95ab88ea36fe","884ed84e8cfc40a296e4099a596651da","d0189f4c1c6840c1a9f22d0dab04f14e","f587d02e00294275b938b8cec20dac76","9c656e5c97194be6be6deb3783c5f173","e04628e035f34d719881ee126c1b448b","934ce098c3d84d0ab3fb3d1c01eb4257","32217b02deda44758ad4b8f0d477054d","7f12a0a1b4a34a63a49719b060de93aa","1b14fbdbaca9462284a9ca4e9b2fff6b","e9ded8905f0744ffbaee8e1b4e842679","66b311b53fc04345ac47f2d472924dbf","6129c8e6e200441487fdd6e255ce1ec0","4499b8e67d0d46b3a2c8cb786105ff4d"]},"execution":{"iopub.status.busy":"2024-09-19T09:29:44.164747Z","iopub.execute_input":"2024-09-19T09:29:44.165162Z","iopub.status.idle":"2024-09-19T09:32:58.007226Z","shell.execute_reply.started":"2024-09-19T09:29:44.165104Z","shell.execute_reply":"2024-09-19T09:32:58.005967Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/148979 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d14712a43354b6f9a30281d6e9c9d0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16533 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bf1d3d9d4e4728815a3428834bba4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7e68f6fbdc4a0596e68ddefa482042"}},"metadata":{}}]},{"cell_type":"code","source":"# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n\nnltk.download(\"punkt\", quiet=True)\n\n# metric = datasets.load_metric(\"rouge\")\nmetric = evaluate.load(\"rouge\")\n\n\ndef postprocess_text(preds, labels):\n#     print(\"preds\",preds)\n#     print(\"labels\",labels)\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n#     print(\"\\n\\n\")\n#     print(\"preds\",preds)\n#     print(\"labels\",labels)\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n#     print(\"eval_preds\",eval_preds)\n    preds, labels = eval_preds\n#     print(\"preds\",preds)\n#     print(\"labels\",labels)\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n#     print(\"decoded_preds\",decoded_preds)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n#     print(\"labels\",labels)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n#     print(\"decoded_labels\",decoded_labels)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n#     print(\"decoded_preds\",decoded_preds)\n#     print(\"decoded_labels\",decoded_labels)\n    result = metric.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n#     print(\"result\",result)\n    # Extract a few results from ROUGE\n    # result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n    result = {key: value * 100 for key, value in result.items()}\n#     print(\"result\",result)\n    prediction_lens = [\n        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n    ]\n#     print(\"prediction_lens\",prediction_lens)\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n#     print(\"result\",result)\n    return result","metadata":{"id":"vqkXcGLN54jX","outputId":"96d151bc-a375-4af2-a933-7bed0b67179e","colab":{"base_uri":"https://localhost:8080/","height":69,"referenced_widgets":["67691184378a460fabbaa9deffbf2942","1c140e47458344daa17ce2135969ab66","412ccc11949e4e7493ba9add45c32ac0","27e7a671a85d4771899b7a39021798b3","7e153a93915a4e0887827d46f7f6c42d","78538f7b0f544cb29717a61ff6243ba8","4348ac706dad4b6cbc6f4e3f4f61a625","bc5ed0f6efbd43e8b94f1738a6eeb025","4e05224098c24064bec6be13e8195c89","1b01b2e24f664d2799a03bf5bca74d38","55a1ef07e4a247d7bad3ffabd3e016a1"]},"execution":{"iopub.status.busy":"2024-09-19T09:32:58.009007Z","iopub.execute_input":"2024-09-19T09:32:58.009899Z","iopub.status.idle":"2024-09-19T09:33:00.074985Z","shell.execute_reply.started":"2024-09-19T09:32:58.009843Z","shell.execute_reply":"2024-09-19T09:33:00.073942Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d364486dc44f918bf425c66462bf33"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"results\",\n    num_train_epochs=1,  # demo\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=4,  # demo\n    per_device_eval_batch_size=4,\n    learning_rate=3e-05,\n    warmup_steps=500,\n    weight_decay=0.1,\n    label_smoothing_factor=0.1,\n    predict_with_generate=True,\n    logging_dir=\"logs\",\n    logging_steps=500,\n    save_total_limit=3,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"id":"KoCAVHM0_GPD","execution":{"iopub.status.busy":"2024-09-19T09:33:00.076268Z","iopub.execute_input":"2024-09-19T09:33:00.076565Z","iopub.status.idle":"2024-09-19T09:33:00.968942Z","shell.execute_reply.started":"2024-09-19T09:33:00.076533Z","shell.execute_reply":"2024-09-19T09:33:00.967858Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"if WANDB_INTEGRATION:\n    wandb_run = wandb.init(\n        project=\"bart-large-cnn-newsroom\",\n        config={\n            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n            \"learning_rate\": training_args.learning_rate,\n            \"dataset\": \"newsroom\",\n            \"model_name\": model_name,\n        },\n    )\n\n    now = datetime.now()\n    current_time = now.strftime(\"%H%M%S\")\n    wandb_run.name = \"run_\" + current_time","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"DYlaphgGorhd","outputId":"82ac127e-1ff2-4e88-deb5-a76b16038d58","execution":{"iopub.status.busy":"2024-09-19T09:33:00.970232Z","iopub.execute_input":"2024-09-19T09:33:00.970537Z","iopub.status.idle":"2024-09-19T09:33:25.732149Z","shell.execute_reply.started":"2024-09-19T09:33:00.970504Z","shell.execute_reply":"2024-09-19T09:33:25.730763Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:msors8ah) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">colorful-haze-7</strong> at: <a href='https://wandb.ai/logeshkc-student/uncategorized/runs/msors8ah' target=\"_blank\">https://wandb.ai/logeshkc-student/uncategorized/runs/msors8ah</a><br/> View project at: <a href='https://wandb.ai/logeshkc-student/uncategorized' target=\"_blank\">https://wandb.ai/logeshkc-student/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240919_091417-msors8ah/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:msors8ah). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240919_093300-3gzlqflw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom/runs/3gzlqflw' target=\"_blank\">exalted-dew-3</a></strong> to <a href='https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom' target=\"_blank\">https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom/runs/3gzlqflw' target=\"_blank\">https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom/runs/3gzlqflw</a>"},"metadata":{}}]},{"cell_type":"code","source":"eval_results_before = trainer.evaluate()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764},"id":"aCcTQ-EFlqvB","outputId":"7ad52339-e0a0-4920-9520-a62fd1ea0db9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_results_before","metadata":{"execution":{"iopub.status.busy":"2024-09-19T04:34:35.952565Z","iopub.execute_input":"2024-09-19T04:34:35.952970Z","iopub.status.idle":"2024-09-19T04:34:35.960869Z","shell.execute_reply.started":"2024-09-19T04:34:35.952927Z","shell.execute_reply":"2024-09-19T04:34:35.959813Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.7836737632751465,\n 'eval_model_preparation_time': 0.01,\n 'eval_rouge1': 0.1535,\n 'eval_rouge2': 0.0251,\n 'eval_rougeL': 0.1078,\n 'eval_rougeLsum': 0.1271,\n 'eval_gen_len': 68.256,\n 'eval_runtime': 6376.6833,\n 'eval_samples_per_second': 2.583,\n 'eval_steps_per_second': 0.646}"},"metadata":{}}]},{"cell_type":"code","source":"%%wandb\n# uncomment to display Wandb charts\n\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":595},"id":"deo-8I5FluQ8","outputId":"763a373b-123f-46d8-9fb5-6e64fd3ec289","execution":{"iopub.status.busy":"2024-09-19T09:36:24.298132Z","iopub.execute_input":"2024-09-19T09:36:24.298561Z","iopub.status.idle":"2024-09-19T13:15:03.198072Z","shell.execute_reply.started":"2024-09-19T09:36:24.298523Z","shell.execute_reply":"2024-09-19T13:15:03.197104Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<wandb.jupyter.IFrame at 0x7b7c80b10100>","text/html":"<iframe src='https://wandb.ai/logeshkc-student/bart-large-cnn-newsroom/runs/3gzlqflw?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='37245' max='37245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [37245/37245 3:38:36, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>4.427700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.401600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.358100</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.346000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>4.360900</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>4.350700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>4.289500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>4.301600</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>4.275700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>4.247200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>4.266100</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>4.245100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>4.258300</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>4.270900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>4.259800</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>4.227300</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>4.204300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>4.207600</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>4.219900</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>4.207800</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>4.212300</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>4.201800</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>4.184700</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>4.174100</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>4.179700</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>4.175100</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>4.164600</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>4.139500</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>4.163900</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>4.177500</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>4.117500</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>4.131100</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>4.151700</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>4.151400</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>4.122300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>4.092000</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>4.130800</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>4.074400</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>4.106600</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>4.081000</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>4.103600</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>4.067000</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>4.094500</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>4.086900</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>4.099200</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>4.054300</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>4.074400</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>4.031000</td>\n    </tr>\n    <tr>\n      <td>24500</td>\n      <td>4.026300</td>\n    </tr>\n    <tr>\n      <td>25000</td>\n      <td>4.050100</td>\n    </tr>\n    <tr>\n      <td>25500</td>\n      <td>4.058000</td>\n    </tr>\n    <tr>\n      <td>26000</td>\n      <td>4.045900</td>\n    </tr>\n    <tr>\n      <td>26500</td>\n      <td>4.004200</td>\n    </tr>\n    <tr>\n      <td>27000</td>\n      <td>4.030700</td>\n    </tr>\n    <tr>\n      <td>27500</td>\n      <td>4.034300</td>\n    </tr>\n    <tr>\n      <td>28000</td>\n      <td>4.011100</td>\n    </tr>\n    <tr>\n      <td>28500</td>\n      <td>4.030500</td>\n    </tr>\n    <tr>\n      <td>29000</td>\n      <td>4.018400</td>\n    </tr>\n    <tr>\n      <td>29500</td>\n      <td>4.003500</td>\n    </tr>\n    <tr>\n      <td>30000</td>\n      <td>4.031900</td>\n    </tr>\n    <tr>\n      <td>30500</td>\n      <td>4.023000</td>\n    </tr>\n    <tr>\n      <td>31000</td>\n      <td>4.022700</td>\n    </tr>\n    <tr>\n      <td>31500</td>\n      <td>3.965100</td>\n    </tr>\n    <tr>\n      <td>32000</td>\n      <td>3.996600</td>\n    </tr>\n    <tr>\n      <td>32500</td>\n      <td>3.945400</td>\n    </tr>\n    <tr>\n      <td>33000</td>\n      <td>3.964100</td>\n    </tr>\n    <tr>\n      <td>33500</td>\n      <td>3.969300</td>\n    </tr>\n    <tr>\n      <td>34000</td>\n      <td>4.001300</td>\n    </tr>\n    <tr>\n      <td>34500</td>\n      <td>3.954200</td>\n    </tr>\n    <tr>\n      <td>35000</td>\n      <td>3.961700</td>\n    </tr>\n    <tr>\n      <td>35500</td>\n      <td>3.976400</td>\n    </tr>\n    <tr>\n      <td>36000</td>\n      <td>3.995800</td>\n    </tr>\n    <tr>\n      <td>36500</td>\n      <td>4.000900</td>\n    </tr>\n    <tr>\n      <td>37000</td>\n      <td>3.964400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=37245, training_loss=4.125256819615573, metrics={'train_runtime': 13117.7625, 'train_samples_per_second': 11.357, 'train_steps_per_second': 2.839, 'total_flos': 8.068776332417434e+16, 'train_loss': 4.125256819615573, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"eval_results_after = trainer.evaluate()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":746},"id":"SMtNVVXqnzWc","outputId":"50d75203-d74e-405a-e76d-6b9d7ec217ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if WANDB_INTEGRATION:\n    wandb_run.finish()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549,"referenced_widgets":["50387fd8bb3d42d3a7e4bd6792b4361f","1693edd15df64bb8b92aff1e38afbbb0","989bf836f4744876a8a3bf4915c8d1f4","55bf703c4da54e0387fef342cfeac073","4f4c5e41701f43f4a40081fc9bad09da","107098a7f3d04c23941991632b8d942f","0b153982537a4f8a927e980481ef2fc4","c84b0ed37d824200b68483672d1f6e13"]},"id":"WIfrQChNocLi","outputId":"dd04099d-693e-4053-e271-652773cc6a2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_results_after","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyV-DIGjvPG3","outputId":"5bed3fb2-ce75-47a4-8e6e-706e832bcfa2","execution":{"iopub.status.busy":"2024-09-19T09:11:03.360851Z","iopub.execute_input":"2024-09-19T09:11:03.361218Z","iopub.status.idle":"2024-09-19T09:11:03.680919Z","shell.execute_reply.started":"2024-09-19T09:11:03.361179Z","shell.execute_reply":"2024-09-19T09:11:03.679767Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_results_after\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'eval_results_after' is not defined"],"ename":"NameError","evalue":"name 'eval_results_after' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Convert the metric results into lists for element-wise operations\nmetrics = list(eval_results_before.keys())\nbefore_values = list(eval_results_before.values())\nafter_values = list(eval_results_after.values())\n\n# Compute the differences\ndifferences = [after - before for before, after in zip(before_values, after_values)]\n\nprint(len(metrics),len(before_values),len(after_values),len(differences))\n# Combine the results into a DataFrame for comparison\ncomparison_df = pd.DataFrame({\n    'Metric': metrics,\n    'Before Training': before_values,\n    'After Training': after_values[:-1],\n    'Difference': differences\n})\n\nprint(comparison_df)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Auqfrl1toerc","outputId":"02fb8cab-fc2d-4cf9-8e10-b08c49f73159","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_results_after.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EbiXvsA5RES","outputId":"02f442db-d11d-49a7-afaa-67823c1e01e0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_results_before.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUpYpDfH5UyU","outputId":"ddb0e408-3f5b-47a4-c46e-7f56259f2127","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test dataset\ntest_results = trainer.predict(test_data)\n\n# The test results contain predictions and metrics (if compute_metrics is defined)\npredictions, labels, metrics = test_results\n\n# Print predictions and test metrics\nprint(\"Test Metrics:\", metrics)\nprint(\"Predictions:\", predictions)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"N_-Llk0qxwPt","outputId":"e06a9664-53f3-4801-93fc-f9cacf31712d"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 11:53]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":"eval_preds <transformers.trainer_utils.EvalPrediction object at 0x7d5d24137820>\n\npreds [[    2     0  2522 ...     1     1     1]\n\n [    2     0   100 ...     1     1     1]\n\n [    2     0   970 ...     1     1     1]\n\n ...\n\n [    2     0   387 ...     1     1     1]\n\n [    2     0 14043 ...     1     1     1]\n\n [    2     0   846 ...     1     1     1]]\n\nlabels [[    0 45093   184 ...     1     1     1]\n\n [    0 32401 33280 ...     1     1     1]\n\n [    0   771 27698 ...     1     1     1]\n\n ...\n\n [    0   133  3390 ...     1     1     1]\n\n [    0 32139 12579 ...     1     1     1]\n\n [    0   846   833 ...     1     1     1]]\n\ndecoded_preds ['Our habit of carrying our phones constantly makes them more prone to breakage. Not all phone mishaps can be fixed but many can either at home or by professionals. For remedies to 10 common cellphone accidents read on. For more information on how to fix your phone click here.', 'I visited Saudi Arabia in September 2008 arriving in Riyadh the day Hurricane Ike smashed into Houston knocking out power for my wife and two little boys. Nothing I could do about it but watch storm footage on CNN International while drinking nonalcoholic Budweiser no booze in the kingdom. That was the same month that the financial crisis hit and on the day of Lehman Brothers  LEHMQ news people collapse.', 'There are serious numerical anomalies in the debate you are moderating.You may want to check it out. I am sorry and certainly I believe the political operative who quite possibly has been behind this voterigging has to be at least privately reprimanded by his party. Pulling this under the rug would be quite counterproductive.', 'A tradition in Washington since 1983 these 12 guys wear snouts dresses and garden hats to Redskins games. The Hogettes several of whom are in the Pro Football Hall of Fames Hall of Fans have made charities a significant part of their group. Over the years theyve donated millions of dollars to charitable causes.', 'Castao who leads the Colombian paramilitaries reveals that he was trained in the arts of war in Israelas a young man of 18 in the 1980s. He glowingly adds âI copied the concept of paramilitary forces from the Israelisâ in his chapterlong account of his Israel experiences.', 'Leonardo da Vinci drew the first ever landscape on 5 August 1473. The invention of landscape painting is one of the great moments of European art. Painting nature is a way to get inside yourself. To this day people enjoy doing watercolours in the outdoors as a form of meditation.', 'Dubbed Spy Booth the image of three spooks appeared on the corner of two residential streets in Cheltenham Gloucestershire. It was suspected that the work was by Banksy but the artist has confirmed it on the QA section of his website. The admission comes in the wake of the storm over surveillance by GCHQ and the National Security Agency.', 'Barrymore and 22monthold daughter Olive hit up the popular Childrens Beach for some fun in the sun. The family then headed to dinner at Lola Burger where Barrymore dined on a New England summer staple a lobster roll. She is also mom to newborn daughter. whom she and husband Will Kopelman.', 'Dr. Holmes called attention to prevalence of small families among the highly intelligent. In 1929 he said that the future would see a larger proportion of Negroes in the North than in the South. In 1939 he urged the substitution of a Darwinian code of morals for the ancient Hebraic and Christian codes.', 'Vine Alternative Investments is raising 300 million for a new fund that would invest in film and television show royalty streams. Vine has set a 400 million hard cap for the new fund with a 5 million minimum investment for institutions. The New Yorkbased firm has invested in more than 400 films including Ace Ventura Black Hawk Down DreamGirls and Rent.']\n\nlabels [[    0 45093   184 ...     1     1     1]\n\n [    0 32401 33280 ...     1     1     1]\n\n [    0   771 27698 ...     1     1     1]\n\n ...\n\n [    0   133  3390 ...     1     1     1]\n\n [    0 32139 12579 ...     1     1     1]\n\n [    0   846   833 ...     1     1     1]]\n\ndecoded_labels ['Simple home remedies for repairing your mobile phoneand when to get professional help.', 'Hurricane Ike Ramadan and the billionaire prince.', 'WITH a month to go until Mexicos presidential election everyone is thinking about politics. Or are they A new poll asking which news stories have caught peoples attention suggests that campaign hasnt grabbed everyone.', 'When Ed Anzalone relinquished his role as quotFireman Edquot this week he wasnt just hanging up his hat. He was leaving an exclusive gro.', 'PâI learned an infinite amount of things in Israel and to that country I owe part of my essence my human and military achievementsâ said Colombian paramilitary leader and indicted drug trafficker Carlos Castao in his ghostwritten autobiography Mi Confesin.P', 'The history books say that western Renaissance artists invented landscape painting. Not if you believe a new VA exhibition of Chinese art writes Jonathan Jones', 'Guerrilla graffiti artist admits to painting three 1950sstyle spooks near listening centre in Cheltenham', 'The actress spent time at the beach and pool with her elder daughter Olive', 'Holmes Saml J 95', 'Vine is latest in recent string of income funds to hit the private equity market.']\n\npreds ['Our habit of carrying our phones constantly makes them more prone to breakage. Not all phone mishaps can be fixed but many can either at home or by professionals. For remedies to 10 common cellphone accidents read on. For more information on how to fix your phone click here.', 'I visited Saudi Arabia in September 2008 arriving in Riyadh the day Hurricane Ike smashed into Houston knocking out power for my wife and two little boys. Nothing I could do about it but watch storm footage on CNN International while drinking nonalcoholic Budweiser no booze in the kingdom. That was the same month that the financial crisis hit and on the day of Lehman Brothers  LEHMQ news people collapse.', 'There are serious numerical anomalies in the debate you are moderating.You may want to check it out. I am sorry and certainly I believe the political operative who quite possibly has been behind this voterigging has to be at least privately reprimanded by his party. Pulling this under the rug would be quite counterproductive.', 'A tradition in Washington since 1983 these 12 guys wear snouts dresses and garden hats to Redskins games. The Hogettes several of whom are in the Pro Football Hall of Fames Hall of Fans have made charities a significant part of their group. Over the years theyve donated millions of dollars to charitable causes.', 'Castao who leads the Colombian paramilitaries reveals that he was trained in the arts of war in Israelas a young man of 18 in the 1980s. He glowingly adds âI copied the concept of paramilitary forces from the Israelisâ in his chapterlong account of his Israel experiences.', 'Leonardo da Vinci drew the first ever landscape on 5 August 1473. The invention of landscape painting is one of the great moments of European art. Painting nature is a way to get inside yourself. To this day people enjoy doing watercolours in the outdoors as a form of meditation.', 'Dubbed Spy Booth the image of three spooks appeared on the corner of two residential streets in Cheltenham Gloucestershire. It was suspected that the work was by Banksy but the artist has confirmed it on the QA section of his website. The admission comes in the wake of the storm over surveillance by GCHQ and the National Security Agency.', 'Barrymore and 22monthold daughter Olive hit up the popular Childrens Beach for some fun in the sun. The family then headed to dinner at Lola Burger where Barrymore dined on a New England summer staple a lobster roll. She is also mom to newborn daughter. whom she and husband Will Kopelman.', 'Dr. Holmes called attention to prevalence of small families among the highly intelligent. In 1929 he said that the future would see a larger proportion of Negroes in the North than in the South. In 1939 he urged the substitution of a Darwinian code of morals for the ancient Hebraic and Christian codes.', 'Vine Alternative Investments is raising 300 million for a new fund that would invest in film and television show royalty streams. Vine has set a 400 million hard cap for the new fund with a 5 million minimum investment for institutions. The New Yorkbased firm has invested in more than 400 films including Ace Ventura Black Hawk Down DreamGirls and Rent.']\n\nlabels ['Simple home remedies for repairing your mobile phoneand when to get professional help.', 'Hurricane Ike Ramadan and the billionaire prince.', 'WITH a month to go until Mexicos presidential election everyone is thinking about politics. Or are they A new poll asking which news stories have caught peoples attention suggests that campaign hasnt grabbed everyone.', 'When Ed Anzalone relinquished his role as quotFireman Edquot this week he wasnt just hanging up his hat. He was leaving an exclusive gro.', 'PâI learned an infinite amount of things in Israel and to that country I owe part of my essence my human and military achievementsâ said Colombian paramilitary leader and indicted drug trafficker Carlos Castao in his ghostwritten autobiography Mi Confesin.P', 'The history books say that western Renaissance artists invented landscape painting. Not if you believe a new VA exhibition of Chinese art writes Jonathan Jones', 'Guerrilla graffiti artist admits to painting three 1950sstyle spooks near listening centre in Cheltenham', 'The actress spent time at the beach and pool with her elder daughter Olive', 'Holmes Saml J 95', 'Vine is latest in recent string of income funds to hit the private equity market.']\n\n\n\n\n\n\n\npreds ['Our habit of carrying our phones constantly makes them more prone to breakage.\\nNot all phone mishaps can be fixed but many can either at home or by professionals.\\nFor remedies to 10 common cellphone accidents read on.\\nFor more information on how to fix your phone click here.', 'I visited Saudi Arabia in September 2008 arriving in Riyadh the day Hurricane Ike smashed into Houston knocking out power for my wife and two little boys.\\nNothing I could do about it but watch storm footage on CNN International while drinking nonalcoholic Budweiser no booze in the kingdom.\\nThat was the same month that the financial crisis hit and on the day of Lehman Brothers  LEHMQ news people collapse.', 'There are serious numerical anomalies in the debate you are moderating.You may want to check it out.\\nI am sorry and certainly I believe the political operative who quite possibly has been behind this voterigging has to be at least privately reprimanded by his party.\\nPulling this under the rug would be quite counterproductive.', 'A tradition in Washington since 1983 these 12 guys wear snouts dresses and garden hats to Redskins games.\\nThe Hogettes several of whom are in the Pro Football Hall of Fames Hall of Fans have made charities a significant part of their group.\\nOver the years theyve donated millions of dollars to charitable causes.', 'Castao who leads the Colombian paramilitaries reveals that he was trained in the arts of war in Israelas a young man of 18 in the 1980s.\\nHe glowingly adds âI copied the concept of paramilitary forces from the Israelisâ in his chapterlong account of his Israel experiences.', 'Leonardo da Vinci drew the first ever landscape on 5 August 1473.\\nThe invention of landscape painting is one of the great moments of European art.\\nPainting nature is a way to get inside yourself.\\nTo this day people enjoy doing watercolours in the outdoors as a form of meditation.', 'Dubbed Spy Booth the image of three spooks appeared on the corner of two residential streets in Cheltenham Gloucestershire.\\nIt was suspected that the work was by Banksy but the artist has confirmed it on the QA section of his website.\\nThe admission comes in the wake of the storm over surveillance by GCHQ and the National Security Agency.', 'Barrymore and 22monthold daughter Olive hit up the popular Childrens Beach for some fun in the sun.\\nThe family then headed to dinner at Lola Burger where Barrymore dined on a New England summer staple a lobster roll.\\nShe is also mom to newborn daughter.\\nwhom she and husband Will Kopelman.', 'Dr. Holmes called attention to prevalence of small families among the highly intelligent.\\nIn 1929 he said that the future would see a larger proportion of Negroes in the North than in the South.\\nIn 1939 he urged the substitution of a Darwinian code of morals for the ancient Hebraic and Christian codes.', 'Vine Alternative Investments is raising 300 million for a new fund that would invest in film and television show royalty streams.\\nVine has set a 400 million hard cap for the new fund with a 5 million minimum investment for institutions.\\nThe New Yorkbased firm has invested in more than 400 films including Ace Ventura Black Hawk Down DreamGirls and Rent.']\n\nlabels ['Simple home remedies for repairing your mobile phoneand when to get professional help.', 'Hurricane Ike Ramadan and the billionaire prince.', 'WITH a month to go until Mexicos presidential election everyone is thinking about politics.\\nOr are they A new poll asking which news stories have caught peoples attention suggests that campaign hasnt grabbed everyone.', 'When Ed Anzalone relinquished his role as quotFireman Edquot this week he wasnt just hanging up his hat.\\nHe was leaving an exclusive gro.', 'PâI learned an infinite amount of things in Israel and to that country I owe part of my essence my human and military achievementsâ said Colombian paramilitary leader and indicted drug trafficker Carlos Castao in his ghostwritten autobiography Mi Confesin.P', 'The history books say that western Renaissance artists invented landscape painting.\\nNot if you believe a new VA exhibition of Chinese art writes Jonathan Jones', 'Guerrilla graffiti artist admits to painting three 1950sstyle spooks near listening centre in Cheltenham', 'The actress spent time at the beach and pool with her elder daughter Olive', 'Holmes Saml J 95', 'Vine is latest in recent string of income funds to hit the private equity market.']\n\ndecoded_preds ['Our habit of carrying our phones constantly makes them more prone to breakage.\\nNot all phone mishaps can be fixed but many can either at home or by professionals.\\nFor remedies to 10 common cellphone accidents read on.\\nFor more information on how to fix your phone click here.', 'I visited Saudi Arabia in September 2008 arriving in Riyadh the day Hurricane Ike smashed into Houston knocking out power for my wife and two little boys.\\nNothing I could do about it but watch storm footage on CNN International while drinking nonalcoholic Budweiser no booze in the kingdom.\\nThat was the same month that the financial crisis hit and on the day of Lehman Brothers  LEHMQ news people collapse.', 'There are serious numerical anomalies in the debate you are moderating.You may want to check it out.\\nI am sorry and certainly I believe the political operative who quite possibly has been behind this voterigging has to be at least privately reprimanded by his party.\\nPulling this under the rug would be quite counterproductive.', 'A tradition in Washington since 1983 these 12 guys wear snouts dresses and garden hats to Redskins games.\\nThe Hogettes several of whom are in the Pro Football Hall of Fames Hall of Fans have made charities a significant part of their group.\\nOver the years theyve donated millions of dollars to charitable causes.', 'Castao who leads the Colombian paramilitaries reveals that he was trained in the arts of war in Israelas a young man of 18 in the 1980s.\\nHe glowingly adds âI copied the concept of paramilitary forces from the Israelisâ in his chapterlong account of his Israel experiences.', 'Leonardo da Vinci drew the first ever landscape on 5 August 1473.\\nThe invention of landscape painting is one of the great moments of European art.\\nPainting nature is a way to get inside yourself.\\nTo this day people enjoy doing watercolours in the outdoors as a form of meditation.', 'Dubbed Spy Booth the image of three spooks appeared on the corner of two residential streets in Cheltenham Gloucestershire.\\nIt was suspected that the work was by Banksy but the artist has confirmed it on the QA section of his website.\\nThe admission comes in the wake of the storm over surveillance by GCHQ and the National Security Agency.', 'Barrymore and 22monthold daughter Olive hit up the popular Childrens Beach for some fun in the sun.\\nThe family then headed to dinner at Lola Burger where Barrymore dined on a New England summer staple a lobster roll.\\nShe is also mom to newborn daughter.\\nwhom she and husband Will Kopelman.', 'Dr. Holmes called attention to prevalence of small families among the highly intelligent.\\nIn 1929 he said that the future would see a larger proportion of Negroes in the North than in the South.\\nIn 1939 he urged the substitution of a Darwinian code of morals for the ancient Hebraic and Christian codes.', 'Vine Alternative Investments is raising 300 million for a new fund that would invest in film and television show royalty streams.\\nVine has set a 400 million hard cap for the new fund with a 5 million minimum investment for institutions.\\nThe New Yorkbased firm has invested in more than 400 films including Ace Ventura Black Hawk Down DreamGirls and Rent.']\n\ndecoded_labels ['Simple home remedies for repairing your mobile phoneand when to get professional help.', 'Hurricane Ike Ramadan and the billionaire prince.', 'WITH a month to go until Mexicos presidential election everyone is thinking about politics.\\nOr are they A new poll asking which news stories have caught peoples attention suggests that campaign hasnt grabbed everyone.', 'When Ed Anzalone relinquished his role as quotFireman Edquot this week he wasnt just hanging up his hat.\\nHe was leaving an exclusive gro.', 'PâI learned an infinite amount of things in Israel and to that country I owe part of my essence my human and military achievementsâ said Colombian paramilitary leader and indicted drug trafficker Carlos Castao in his ghostwritten autobiography Mi Confesin.P', 'The history books say that western Renaissance artists invented landscape painting.\\nNot if you believe a new VA exhibition of Chinese art writes Jonathan Jones', 'Guerrilla graffiti artist admits to painting three 1950sstyle spooks near listening centre in Cheltenham', 'The actress spent time at the beach and pool with her elder daughter Olive', 'Holmes Saml J 95', 'Vine is latest in recent string of income funds to hit the private equity market.']\n\nresult {'rouge1': 0.1343396508294749, 'rouge2': 0.016068657787273684, 'rougeL': 0.0989185672467187, 'rougeLsum': 0.11217078601186245}\n\nresult {'rouge1': 13.433965082947491, 'rouge2': 1.6068657787273684, 'rougeL': 9.89185672467187, 'rougeLsum': 11.217078601186245}\n\nprediction_lens [58, 84, 67, 64, 62, 62, 75, 67, 64, 70]\n\nresult {'rouge1': 0.1343, 'rouge2': 0.0161, 'rougeL': 0.0989, 'rougeLsum': 0.1122, 'gen_len': 67.3}\n"},{"output_type":"error","ename":"Error","evalue":"You must call wandb.init() before wandb.log()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d81db09095e4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The test results contain predictions and metrics (if compute_metrics is defined)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     def prediction_step(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3759\u001b[0m         )\n\u001b[1;32m   3760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_and_update_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_predict\u001b[0;34m(self, args, state, control, metrics)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_predict\u001b[0;34m(self, args, state, control, metrics, **kwargs)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewrite_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"]}]},{"cell_type":"code","source":"!pip install transformers huggingface_hub\n!huggingface-cli login","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwEQCWFgyqlC","outputId":"660adb98-c14d-4224-bcf6-f4aadf574d3e","execution":{"iopub.status.busy":"2024-09-19T13:30:23.503250Z","iopub.execute_input":"2024-09-19T13:30:23.503756Z","iopub.status.idle":"2024-09-19T13:31:12.544560Z","shell.execute_reply.started":"2024-09-19T13:30:23.503713Z","shell.execute_reply":"2024-09-19T13:31:12.543531Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\nEnter your token (input will not be visible): Traceback (most recent call last):\n  File \"/opt/conda/bin/huggingface-cli\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n    service.run()\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 115, in login\n    interpreter_login(new_session=new_session, write_permission=write_permission)\n  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 191, in interpreter_login\n    token = getpass(\"Enter your token (input will not be visible): \")\n  File \"/opt/conda/lib/python3.10/getpass.py\", line 77, in unix_getpass\n    passwd = _raw_input(prompt, stream, input=input)\n  File \"/opt/conda/lib/python3.10/getpass.py\", line 146, in _raw_input\n    line = input.readline()\n  File \"/opt/conda/lib/python3.10/codecs.py\", line 319, in decode\n    def decode(self, input, final=False):\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:31:44.205263Z","iopub.execute_input":"2024-09-19T13:31:44.206012Z","iopub.status.idle":"2024-09-19T13:31:44.523186Z","shell.execute_reply.started":"2024-09-19T13:31:44.205970Z","shell.execute_reply":"2024-09-19T13:31:44.522174Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import create_repo\n\n# Replace 'your-username' with your HF username and 'your-model-name' with the desired model repo name\nrepo_name = \"Logeshkc/bart-large-cnn-newsroom-500k\"\ncreate_repo(repo_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"HqlHmVuoyraJ","outputId":"fae0a686-fb48-498b-9e3c-318921e101b3","execution":{"iopub.status.busy":"2024-09-19T13:32:44.655367Z","iopub.execute_input":"2024-09-19T13:32:44.656254Z","iopub.status.idle":"2024-09-19T13:32:45.119773Z","shell.execute_reply.started":"2024-09-19T13:32:44.656200Z","shell.execute_reply":"2024-09-19T13:32:45.118816Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/Logeshkc/bart-large-cnn-newsroom-500k', endpoint='https://huggingface.co', repo_type='model', repo_id='Logeshkc/bart-large-cnn-newsroom-500k')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Assuming you have the trained model and tokenizer\n# model = AutoModelForSeq2SeqLM.from_pretrained(\"path_to_your_model\")\n# tokenizer = AutoTokenizer.from_pretrained(\"path_to_your_tokenizer\")\n\n# Save your model and tokenizer locally before pushing\nmodel.save_pretrained(\"bart-large-cnn-newsroom-500k\")\ntokenizer.save_pretrained(\"bart-large-cnn-newsroom-500k\")\n\n# Now push them to Hugging Face Hub\nmodel.push_to_hub(repo_name)\ntokenizer.push_to_hub(repo_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["1826726d26a7414b945e8ca9343be264","aa14e71b2e754c96b8ab3c53b36af066","c91f427af63e4da2b4235af00d2e549e","5d1e9e3cb6334a07b2f3eeb8d65dbe94","eff808a76f2f4d27bd5aea6404ec640a","fe6c6893fc614194b0c15420eef84534","f0fc6f87b73f44d1aa4ac620d865f7dd","cc1f43f184a04c2d85107ed9403447c5","4b51c00e12634564b3fc274907e5fc16","30c0e26666db452493bde1bb58202a98","0deb1f02e16243f1a6e70e0dfc07676a","f9fa392542bc4631b3ec1d1f8d3e4cbe","a800850a4fa74e11aff0491448eaaafb","474d6173d7c648b381fd4aa623e26cfc","1e6a7c50b0854fa084429d44c2af6d0c","391127497fb44b819c35daac929a7890","e3aa91967a0346fa9cb9ddd4f15c6174","62b79ee93bc14a4e8e5da5df21fb8e5b","5499836a37ee496cb204bee0a55d0b55","25a04dc8d51748569c0fd06f938169a3","0460fcb239fe4d88be3df55545df7008","de2216fa268b435094278ec3d4dcf579"]},"id":"0ANZeqaAy1C0","outputId":"60d56727-7f8b-409f-9808-6995a0c3c792","execution":{"iopub.status.busy":"2024-09-19T13:33:00.154979Z","iopub.execute_input":"2024-09-19T13:33:00.155772Z","iopub.status.idle":"2024-09-19T13:34:27.057854Z","shell.execute_reply.started":"2024-09-19T13:33:00.155732Z","shell.execute_reply":"2024-09-19T13:34:27.056853Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29bd087ced814cecbc5e81b79b0d8281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03fa814f6b4a4e5c872d516bf9b2a5d2"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Logeshkc/bart-large-cnn-newsroom-500k/commit/13f09ec8b706b1e3f3756e2f850f1d0771daa34a', commit_message='Upload tokenizer', commit_description='', oid='13f09ec8b706b1e3f3756e2f850f1d0771daa34a', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"bart-large-cnn-newsroom-500k\")\ntrainer.push_to_hub(repo_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"kI5PuRIMy7WU","outputId":"24c92926-cc91-4cbc-fe29-3324a22001fb","execution":{"iopub.status.busy":"2024-09-19T13:36:27.972263Z","iopub.execute_input":"2024-09-19T13:36:27.972674Z","iopub.status.idle":"2024-09-19T13:37:54.289471Z","shell.execute_reply.started":"2024-09-19T13:36:27.972638Z","shell.execute_reply":"2024-09-19T13:37:54.288486Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb4dde885544a9c85a119e711fc93f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781ee9ef2e834952b3f268bb96bc77fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f11c79eabe48a09e1068b5cfaaeffa"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Logeshkc/results/commit/92df7db599f0122f83c6b790d8b76fc977a27bd0', commit_message='Logeshkc/bart-large-cnn-newsroom-500k', commit_description='', oid='92df7db599f0122f83c6b790d8b76fc977a27bd0', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\n# Load the model and tokenizer from the hub\nmodel = AutoModelForSeq2SeqLM.from_pretrained(repo_name)\ntokenizer = AutoTokenizer.from_pretrained(repo_name)","metadata":{"id":"4Xg4ayZIzHhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"4GcrwnwQ0yGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"KAwF6L19Hm5g"},"execution_count":null,"outputs":[]}]}